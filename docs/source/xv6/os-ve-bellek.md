---
giscus: 2610ab7f-7904-4bff-aa0a-e654a9142f3f
---

# Ä°ÅŸletim Sistemleri ve Bellek YÃ¶netimi

```{note}
Bu yazÄ±da iÅŸletim sistemleri ve bellek yÃ¶netimi konusundaki notlarÄ±m yer
almaktadÄ±r. YazÄ±nÄ±n baÅŸlarÄ± genel kavramlar ile ilgilidir, son kÄ±smÄ±nda ise
xv6'ya Ã¶zel bilgiler yer almaktadÄ±r. YazÄ±nÄ±n amacÄ± genel iÅŸletim sistemleri
olmadÄ±ÄŸÄ±ndan **kavramlardan kÄ±saca bahsedeceÄŸim.**
```

Ä°ÅŸletim sistemi, bizim iÃ§in temel 3 farklÄ± donanÄ±mÄ± soyutlar: **iÅŸlemci**,
**bellek** ve **disk.**

**Disk**, dosya sistemleri ile soyutlanÄ±r. AslÄ±nda *ham* veri depolama cihazÄ± olan
diskler dosya, klasÃ¶r nedir bilmez. Bunlar dosya sisteminin saÄŸladÄ±ÄŸÄ± bir
soyutlama katmanÄ±dÄ±r. Dosya sistemleri de tipik olarak kernel tarafÄ±nda
gerÃ§ekleÅŸtirilir.

**Ä°ÅŸlemci**, farklÄ± thread'ler arasÄ±nda paylaÅŸtÄ±rÄ±lÄ±r. Thread, iÅŸlemcide koÅŸan bir
iÅŸ parÃ§asÄ±dÄ±r yani CPU'da yÃ¼rÃ¼tÃ¼len komutlar. Bir sistemde aynÄ± anda aktif olan
birden fazla thread olsa da her thread sanki sadece kendisi varmÄ±ÅŸ gibi
iÅŸlemciyi kullanÄ±r. Ä°ÅŸlemci kaynaÄŸÄ±nÄ±n birden fazla thread arasÄ±nda
paylaÅŸtÄ±rÄ±lmasÄ± iÅŸi iÅŸletim sisteminin bir gÃ¶revidir. Linux gibi modern iÅŸletim
sistemlerinin Ã§oÄŸu, *multi-thread* programlamayÄ± desteklerler yani kernel
desteÄŸi ile multi-thread Ã§alÄ±ÅŸan programlar mÃ¼mkÃ¼n olabilmektedir. Process ise
aslÄ±nda iÅŸletim sisteminin uydurduÄŸu bir bileÅŸke veri yapÄ±sÄ±dÄ±r. Yani bir
programÄ±n thread'leri + file descriptor table + bellek yapÄ±landÄ±rmasÄ± bir
process oluÅŸturur. xv6'da bir process sadece tek bir thread'ten oluÅŸabilir.
Elbette kullanÄ±cÄ± kendi kodu ile multi-thread ilÃ¼zyonu yaratabilir fakat xv6
kernelinin bÃ¶yle bir desteÄŸi yoktur. O yÃ¼zden xv6 ile ilgili konularÄ±n Ã§oÄŸunda
`thread` ve `process` kelimeleri aynÄ± anlama geliyor gibi dÃ¼ÅŸÃ¼nÃ¼lebilir. Fakat
process, thread dÄ±ÅŸÄ±nda baÅŸka veri yapÄ±larÄ± da iÃ§eren bir yapÄ±dÄ±r.

```{figure} assets/os-ve-bellek-process.jpg
:align: center

Genel process mantÄ±ÄŸÄ± bu ÅŸekildedir. Buradaki Ã§izimde multi-thread bir uygulama
gÃ¶sterilmiÅŸ, 3 adet thread barÄ±ndÄ±ran. Fakat xv6 bir process iÃ§erisinde
bir adet thread destekliyor. Bu Ã§izim xv6 iÃ§in tamamen doÄŸru deÄŸil fakat genel
mantÄ±k olarak doÄŸru bir gÃ¶sterim.

`struct proc` un en Ã¶nemli elemanlarÄ±ndan birinin file descriptor table olduÄŸundan
bahsetmiÅŸtik. Burada da File Handle olarak ilgili tablodan satÄ±rlar gÃ¶sterilmiÅŸ
aslÄ±nda. Elbette xv6'daki `struct proc` iÃ§erisinde baÅŸka elemanlar da var.

[Kaynak](https://ops-class.org/slides/2016-01-30-processes/deck.html#slide-48)
```

**Bellek**, yani RAM, iÅŸletim sistemi Ã¼zerinde koÅŸan tÃ¼m programlar yani
process'ler ve kernel tarafÄ±ndan aslÄ±nda paylaÅŸÄ±lÄ±yor. Biz bir programÄ±
Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z zaman program, iÅŸletim sistemi tarafÄ±ndan program belleÄŸe
aÃ§Ä±lÄ±yor yani yÃ¼kleniyor. BelleÄŸin tam olarak hangi adresine yÃ¼kleneceÄŸi ise
iÅŸletim sisteminin vereceÄŸi bir karar. Ã‡Ã¼nkÃ¼ bilgisayarda bir adet bellek olduÄŸu
ve bu belleÄŸin birden fazla program tarafÄ±ndan paylaÅŸÄ±lmasÄ± gerektiÄŸi iÃ§in
burada her programa Ã¶nden bir yer ayÄ±rmak mÃ¼mkÃ¼n deÄŸil, adeta bellek alanlarÄ±
Ã§alÄ±ÅŸan programlara kiralanÄ±yor. **Fakat programÄ±n belleÄŸin neresine aÃ§Ä±lacaÄŸÄ±nÄ±
derleme sÄ±rasÄ±nda bilmesi mÃ¼mkÃ¼n deÄŸil.** AyrÄ±ca aynÄ± program iÅŸletim sistemi
tarafÄ±ndan belleÄŸin farklÄ± taraflarÄ±na yerleÅŸtirilebilir. Diyelim ki program
iÃ§erisinde temel load/store instruction'larÄ± yani komutlarÄ± (ya da buyruk) var.
Bu komutlarÄ±n belleÄŸin neresine eriÅŸeceÄŸini bilmesi lazÄ±m. Fakat programÄ±n
belleÄŸin gerÃ§ekten neresinde olduÄŸunu bilmezse bu komutlarÄ±n adresleri ne
olacak? Buna bir Ã§Ã¶zÃ¼m bulunmasÄ± gerekiyor **bu Ã§Ã¶zÃ¼mÃ¼n donanÄ±msal olarak
iÅŸlemci tarafÄ±ndan da desteklenmesi lazÄ±m.** Ä°ÅŸte iÅŸletim sisteminin yaptÄ±ÄŸÄ±
Ã¶nemli soyutlamalardan biri de belleÄŸin soyutlanmasÄ±dÄ±r. Tipik olarak programlar
tÃ¼m belleÄŸin onlara ait olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼rler ve bir **sanal bellek** e eriÅŸirler,
**virtual memory**. Sanal belleÄŸe olan yazma/okuma iÅŸlemlerinin gerÃ§ek, fiziksel
belleÄŸe yani RAM entegresine dÃ¶nÃ¼ÅŸÃ¼mÃ¼, gerÃ§ekte belleÄŸin neresine eriÅŸileceÄŸi
konusu iÅŸlemci desteÄŸi ile saÄŸlanÄ±r. Bu yazÄ±da belleÄŸin soyutlanmasÄ±na yani
sanallaÅŸtÄ±rÄ±lmasÄ±na bakacaÄŸÄ±z. xv6'ye gelmeden Ã¶nce probleme biraz daha genel
bakalÄ±m. Bu konular ile ilgili olan anahtar kelimeler: **virtual memory**,
**paging**, **swapping**, **segmentation**, **position independent code (PIC)**
(kÄ±smen)

## Her Programa Bir Bellek AlanÄ±

YapabileceÄŸimiz kÃ¶tÃ¼ Ã§Ã¶zÃ¼mlerden biri Ã§alÄ±ÅŸabilecek her program iÃ§in fiziksel
olarak bellekte belli bir alanÄ± rezerve etmek ve bunu programa derleme
aÅŸamasÄ±nda sÃ¶ylemek olurdu. Yani diyecektik ki 0-512MB arasÄ± firefox'a ait,
512MB-1G arasÄ± VS Code kullansÄ±n gibi. Elbette burada birÃ§ok problem var,
kesinlikle Ã¶lÃ§eklenebilir bir Ã§Ã¶zÃ¼m deÄŸil. KullanÄ±lmayan programlar iÃ§in rezerve
edilmiÅŸ bellek, baÅŸka programlar tarafÄ±ndan kullanÄ±lamÄ±yor, bu en temel
problemlerden biri. Bu yÃ¶ntemin Ã§alÄ±ÅŸmayacaÄŸÄ± belli oldu.

## Relocation

ProgramlarÄ±n Ã§alÄ±ÅŸmadan Ã¶nce belleÄŸin bir yerlerine yerleÅŸtirilmesi ve bu yerden
baÄŸÄ±msÄ±z olacak ÅŸekilde Ã§alÄ±ÅŸÄ±r hale getirilmesi **relocation** problemi olarak
da biliniyor. Yani programÄ± bellekte Ã§alÄ±ÅŸabilirliÄŸini bozmadan taÅŸÄ±ma iÅŸi
diyebiliriz.

Tarihsel olarak baktÄ±ÄŸÄ±mÄ±zda taa IBM 360 (60'lÄ± yÄ±llar) bilgisayarÄ±ndan itibaren
bu Ã§Ã¶zÃ¼m aranan bir problem olmuÅŸ.

```{figure} assets/os-ve-bellek-ibm360.jpg
:align: center

*IBM System/360 Model 50 CPU, computer operator's console, and peripherals at Volkswagen*

[Kaynak](https://commons.wikimedia.org/wiki/File:Bundesarchiv_B_145_Bild-F038812-0014,_Wolfsburg,_VW_Autowerk.jpg)
```

### Static Relocation

Diyelim ki programÄ± bir dilde yazdÄ±nÄ±z, mesela C, derlediniz ve `JMP 3` gibi bir
komut var, bu bellekteki 3 nolu adresteki kodu Ã§alÄ±ÅŸtÄ±r demek. ProgramÄ±nÄ±z kendisinin
adres 0'dan itibaren yerleÅŸtiÄŸini dÃ¼ÅŸÃ¼nÃ¼yor ama ya Ã¶yle deÄŸilse. Ä°ÅŸte bu durumda
IBM 360 ÅŸÃ¶yle bir ÅŸey yapÄ±yormuÅŸ: Diyelim ki sizin programÄ±nÄ±zÄ± adres 1000'den
itibaren yerleÅŸtirdi. ProgramÄ± diskten belleÄŸe yÃ¼klerken **static relocation**
denen bir teknik kullanÄ±yoru ve tÃ¼m `JMP` komutlarÄ±nÄ±n adresine 1000 ekliyor.
Ã–rneÄŸin `JMP 3` oluyor `JMP 1003`. Bu, programÄ±n *yÃ¼klenirken* modifiye edilmesi
demek. ProgramÄ± baÅŸka bir yere taÅŸÄ±mak iÃ§in de bu relocator yazÄ±lÄ±mÄ±nÄ±n
(programÄ± modifiye eden yazÄ±lÄ±m) tekrar Ã§alÄ±ÅŸmasÄ± gerekiyor. Bu, Ã§ok kullanÄ±ÅŸlÄ±
bir yÃ¶ntem deÄŸil.

### Dynamic Relocation ve Segmentation

Bir de **dynamic relocation** denen bir Ã§Ã¶zÃ¼m tekniÄŸi var. Bu tekniklerde
dÃ¶nÃ¼ÅŸÃ¼m program Ã§alÄ±ÅŸÄ±rken, *belleÄŸe eriÅŸim sÄ±rasÄ±nda* yapÄ±lÄ±yor. Elbette bunun
iÃ§in donanÄ±m desteÄŸi gerekiyor fakat program yÃ¼klenirken iÅŸletim sistemi
tarafÄ±ndan modifiye edilmiyor, sadece bu mekanizmayÄ± saÄŸlayan donanÄ±m
bileÅŸenleri konfigÃ¼re ediliyor. GÃ¼nÃ¼mÃ¼zde iÅŸletim sistemi Ã§alÄ±ÅŸtÄ±ran iÅŸlemcilerin
hemen hemen hepsi kategorideki teknikleri kullanÄ±yor.

Dynamic relocation teknikleri Ã§eÅŸitli, en temellerinden biri **segmentation.**
Burada tÃ¼m program iÃ§in (kod + veri + stack), veya hepsi iÃ§in ayrÄ± ayrÄ± birer
*base register* bulunuyor. Program, kendisi adres 0'daymÄ±ÅŸ gibi Ã§alÄ±ÅŸÄ±yor. Fakat
aslÄ±nda bu bir offset deÄŸer. Ä°ÅŸletim sistemi, programÄ± yÃ¼klediÄŸi zaman bellekte
nereye yerleÅŸtirdiyse ona gÃ¶re bu *base register* larÄ± ayarlÄ±yor. Bir bellek
eriÅŸimi olduÄŸu zaman ise iÅŸlemci donanÄ±mÄ± gidip bellekten eriÅŸeceÄŸi adresi
en temel olarak `gerÃ§ek adres = base register + offset` ÅŸeklinde buluyor.
Program kodlarÄ±nda ise `JMP 3` gibi bir komut olursa (veri eriÅŸimi de benzer
ÅŸekilde), `gerÃ§ek adres = base register + 3` mantÄ±ÄŸÄ± ile hesaplanÄ±yor.

Tarihsel aÃ§Ä±dan baktÄ±ÄŸÄ±mÄ±zda CDC 6600 (1964), Intel 8088 (1979) gibi bilgisayar
ve iÅŸlemciler farklÄ± Ã§alÄ±ÅŸma mantÄ±klarÄ± sergileseler de base + offset mantÄ±ÄŸÄ±nÄ±
destekliyorlar.

Fakat baÅŸka problemler de mevcut

## Fragmentation

Segment'ler tek bir birim, bellekte ard arda olmasÄ± gerekiyor. Diyelim ki
programÄ±nÄ±zÄ±n data segment'i 300 MB yer tutuyor, kesintisiz bir 300 MB'lÄ±k
boÅŸluk bulmanÄ±z lazÄ±m aksi taktirde programÄ± Ã§alÄ±ÅŸtÄ±ramÄ±yorsunuz. Sistem aÃ§Ä±lÄ±p
bazÄ± programlar Ã§alÄ±ÅŸÄ±p, belleÄŸe yÃ¼klenip, bellekten Ã§Ä±karÄ±ldÄ±kÃ§a bellekte
boÅŸluklar oluÅŸmaya baÅŸlÄ±yor, *bellek delik deÅŸik oluyor* adeta. Bu durumda
bellekte toplamda Ã¶rneÄŸin 1 GB boÅŸ alan olsa bile ard arda boÅŸluklardan oluÅŸan
300 MB'lÄ±k bir alan bulunamayabiliyor. Diyelim ki 4 adet 256 MB'lÄ±k boÅŸ yer var
ama 300 MB'lÄ±k segment yine hiÃ§ bir yere girmiyor. Buna **fragmentation**
problemi deniyor. Temel iki Ã§eÅŸidi var: **internal fragmentation** ve **external
fragmentation**. YazÄ±nÄ±n konusu genel OS konularÄ± olmadÄ±ÄŸÄ± iÃ§in detaylara
girmiyorum.

## Virtual Memory ve Paging

GÃ¼nÃ¼mÃ¼zde kullanÄ±lan temel dynamic allocation tekniÄŸi ise **virtual memory**,
TÃ¼rkÃ§e'ye **sanal bellek** (eskiden bir de `sanal bebek` vardÄ±, hehe) olarak
Ã§evrilebilir [^1f]. Burada bellek, **page** yani **sayfa** adÄ±nda minik
parÃ§alara ayrÄ±lÄ±yor. Virtual memory yÃ¶ntemi, 1961 yÄ±lÄ±nda dÃ¼nyanÄ±n ilk sÃ¼per
bilgisayarlarÄ±ndan biri olan
[Atlas](https://en.wikipedia.org/wiki/Atlas_(computer))'ta Ã§alÄ±ÅŸan John
Fotheringham tarafÄ±ndan [kullanÄ±lmÄ±ÅŸ](https://dl.acm.org/profile/81100516822),
yani yÃ¶ntem olarak oldukÃ§a eski.

GÃ¼nÃ¼mÃ¼z iÅŸlemcilerde page boyutu yani page size tipik olarak 4/8 KiB gibi
deÄŸerlerde oluyor ama iÅŸlemcilerin Ã§oÄŸu MiB hatta GiB boyutlarÄ±nda daha bÃ¼yÃ¼k
page size deÄŸerlerini destekliyor. [^2f] Page size'Ä±n bÃ¼yÃ¼k ya da kÃ¼Ã§Ã¼k olmasÄ±nÄ±n
getirdiÄŸi Ã§eÅŸitili avantaj ve dezavantajlar var. Ama bunlar da bu yazÄ±nÄ±n konusu
deÄŸil.

Diyelim ki page size deÄŸerimiz 4 KiB, bu durumda process'in gÃ¶rdÃ¼ÄŸÃ¼ bellek ve
gerÃ§ek fiziksel bellek 4 KiB'lik parÃ§alara bÃ¶lÃ¼nÃ¼yor ve parÃ§alar gerÃ§ek yani
fiziksel belleÄŸin **herhangi bir** 4 KiB'lÄ±k kÄ±sÄ±mlarÄ±na eÅŸleÅŸtiriliyor. Yani
process aÃ§Ä±sÄ±ndan bellek tek parÃ§a ve sÃ¼rekli fakat arka planda olan eÅŸleÅŸme
sayesinde her 4 KiB, fiziksel bellekte ard arda olmayan 4 KiB'lÄ±k bÃ¶lÃ¼me denk
geliyor olabilir.

## Swapping

Virtual memory ile ilgili sÄ±k anÄ±lan terim ve tekniklerden biri de **swapping**
kavramÄ±dÄ±r. Swapping yapÄ±labilmesi iÃ§in virtual memory yani sayfa bazlÄ± bir
bellek yÃ¶netimi zorunlu deÄŸildir, segment bazlÄ± sistemlerde de yapÄ±labilir. Ama
gÃ¼nÃ¼mÃ¼zde artÄ±k standart olan yapÄ± virtual memory + swapping diyebiliriz. Ben de
virtual memory kullanan sitemler Ã¼zerinden anlatmaya devam edeceÄŸim.

Swapping'in amacÄ± fiziksel olarak belleÄŸin yetmediÄŸi durumlarda belleÄŸin bir
kÄ±smÄ±nÄ±n diske, hard disk veya SSD, konulmasÄ±, diske aktarÄ±lan kÄ±smÄ±n baÅŸka
process veya iÅŸler iÃ§in kullanÄ±lmasÄ± ve ihtiyaÃ§ halinde tekrar diskteki bellek
bilgilerinin geri yÃ¼klenmesidir. Linux Ã¼zerinde Ã§alÄ±ÅŸan arkadaÅŸlar zaten `swap`
kelimesi ile Ã¶nceden muhtemelen tanÄ±ÅŸmÄ±ÅŸlardÄ±r. Swapping genellikle sayfalar
Ã¼zerinden olmaktadÄ±r. Yani bir sayfa komple diske aktarÄ±lÄ±r ya da diskten belleÄŸe
geri konur. Elbette bu iÅŸlem Ã§alÄ±ÅŸan program bunun farkÄ±na varmadan yapÄ±lÄ±r.
Burada iÅŸletim sistemi ve iÅŸlemcinin donanÄ±mÄ± rol alÄ±r.

**Genel iÅŸletim sistemi kÄ±smÄ±nÄ± burada kesiyorum.** Fakat dilerseniz `Kaynaklar`
kÄ±smÄ±ndaki kaynaklardan veya beÄŸendiÄŸiniz bir iÅŸletim sistemi kitabÄ±ndan konularÄ±
Ã¶ÄŸrenebilirsiniz. Åimdi xv6 ve RISC-V Ã¶zelinde devam edelim.

## xv6

xv6, RISC-V donanÄ±mÄ±nÄ±n sunduÄŸu paging yÃ¶ntemini kullanan bir iÅŸletim sistemi.
Yani virtual memory destekleniyor. xv6 gibi neredeyse tÃ¼m iÅŸletim sistemlerinde
process'lerin gÃ¶rdÃ¼ÄŸÃ¼ bir **adress space** vardÄ±r. Her process, aynÄ± adress
space'i gÃ¶rÃ¼r. TÃ¼m process'lerin belleÄŸinin tÃ¼mÃ¼nÃ¼n kendilerine ait olduÄŸunu
zanneder (hatta var olan fiziksel bellekten daha bÃ¼yÃ¼k bir bellek gÃ¶rÃ¼rler).
GerÃ§ek bellek ile process'lerin gÃ¶rdÃ¼ÄŸÃ¼ sanal belleÄŸin birbiriyle eÅŸleÅŸtirilmesi
ve yÃ¶netimi iÅŸletim sisteminin Ã§ekirdeÄŸinin kontrolÃ¼nde, RISC-V donanÄ±mÄ± sayesinde
yapÄ±lÄ±r.

### QEMU Sistemi

xv6'yÄ± QEMU Ã¼zerinde emule ediyoruz. Åimdi gelin QEMU tarafÄ±ndan saÄŸlanan
*sanal* RISC-V sisteminin bellek haritasÄ±na bir bakalÄ±m.

Bunun iÃ§in [QEMU'nun kaynak
kodundan](https://github.com/qemu/qemu/blob/master/hw/riscv/virt.c) Ã§eÅŸitli
ipuÃ§larÄ± toplayabiliriz:

```{code-block} c
:caption: hw/riscv/virt.c
:lineno-start: 70
:emphasize-lines: 21

static const MemMapEntry virt_memmap[] = {
  [VIRT_DEBUG] =        {        0x0,         0x100 },
  [VIRT_MROM] =         {     0x1000,        0xf000 },
  [VIRT_TEST] =         {   0x100000,        0x1000 },
  [VIRT_RTC] =          {   0x101000,        0x1000 },
  [VIRT_CLINT] =        {  0x2000000,       0x10000 },
  [VIRT_ACLINT_SSWI] =  {  0x2F00000,        0x4000 },
  [VIRT_PCIE_PIO] =     {  0x3000000,       0x10000 },
  [VIRT_PLATFORM_BUS] = {  0x4000000,     0x2000000 },
  [VIRT_PLIC] =         {  0xc000000, VIRT_PLIC_SIZE(VIRT_CPUS_MAX * 2) },
  [VIRT_APLIC_M] =      {  0xc000000, APLIC_SIZE(VIRT_CPUS_MAX) },
  [VIRT_APLIC_S] =      {  0xd000000, APLIC_SIZE(VIRT_CPUS_MAX) },
  [VIRT_UART0] =        { 0x10000000,         0x100 },
  [VIRT_VIRTIO] =       { 0x10001000,        0x1000 },
  [VIRT_FW_CFG] =       { 0x10100000,          0x18 },
  [VIRT_FLASH] =        { 0x20000000,     0x4000000 },
  [VIRT_IMSIC_M] =      { 0x24000000, VIRT_IMSIC_MAX_SIZE },
  [VIRT_IMSIC_S] =      { 0x28000000, VIRT_IMSIC_MAX_SIZE },
  [VIRT_PCIE_ECAM] =    { 0x30000000,    0x10000000 },
  [VIRT_PCIE_MMIO] =    { 0x40000000,    0x40000000 },
  [VIRT_DRAM] =         { 0x80000000,           0x0 },
};
```

Burada `BaseAddr - Size` Ã§iftlerini gÃ¶rÃ¼yoruz. RAM kÄ±smÄ±nÄ±n base adresinin
`0x80000000` olduÄŸunu gÃ¶rÃ¼yoruz fakat boyutunun 0 olmasÄ± elbette olasÄ± deÄŸil,
baÅŸka bir yerden geliyor olmalÄ±. Kodun ilerleyen kÄ±sÄ±mlarÄ±nda ÅŸÃ¶yle bir satÄ±r
var:

```{code-block} c
:caption: hw/riscv/virt.c
:lineno-start: 1288
:emphasize-lines: 3

/* build the array of physical mem area from base_memmap */
mem_array.address = s->memmap[VIRT_DRAM].base;
mem_array.length = ms->ram_size;
```

BelleÄŸin boyutu muhtemelen bu koda bir yerlerden parametre olarak geliyor.
Burada xv6 repository'sindeki Makefile yardÄ±mcÄ± oluyor:

```{note}
Ä°lerleyen kÄ±sÄ±mlarda [f5b93ef](https://github.com/mit-pdos/xv6-riscv/tree/f5b93ef12f7159f74f80f94729ee4faabe42c360)
nolu commit'i referans alacaÄŸÄ±m.
```

```{code-block} makefile
:caption: Makefile
:lineno-start: 159
:emphasize-lines: 1

QEMUOPTS = -machine virt -bios none -kernel $K/kernel -m 128M -smp $(CPUS) -nographic
QEMUOPTS += -global virtio-mmio.force-legacy=false
QEMUOPTS += -drive file=fs.img,if=none,format=raw,id=x0
```

`-m 128M` argÃ¼manÄ± ile oluÅŸturulan "sanal makine" 128M ile oluÅŸturuluyor.
Bunu xv6 kodunda baÅŸka yerlerde de gÃ¶rÃ¼yoruz:

```{code-block} c
:caption: kernel/memlayout.h
:lineno-start: 44
:emphasize-lines: 5

// the kernel expects there to be RAM
// for use by the kernel and user pages
// from physical address 0x80000000 to PHYSTOP.
#define KERNBASE 0x80000000L
#define PHYSTOP (KERNBASE + 128*1024*1024)
```

xv6'nÄ±n kodunun yorumlarÄ±na bakarsak `0x80000000` ve ilerisindeki 128M'lik alanÄ±n
hem kernel hem de kullanÄ±cÄ± programlarÄ± tarafÄ±ndan kullanÄ±lan bellek alanÄ±
olduÄŸunu gÃ¶rÃ¼yoruz. Yani ÅŸimdilik her ÅŸey tutarlÄ± gidiyor.

---

```{code-block} c
:caption: kernel/memlayout.h
:lineno-start: 3

// qemu -machine virt is set up like this,
// based on qemu's hw/riscv/virt.c:
//
// 00001000 -- boot ROM, provided by qemu
// 02000000 -- CLINT
// 0C000000 -- PLIC
// 10000000 -- uart0
// 10001000 -- virtio disk
// 80000000 -- boot ROM jumps here in machine mode
//             -kernel loads the kernel here
// unused RAM after 80000000.
```

YukarÄ±daki yorumlardan baÅŸka bilgiler de Ã§Ä±kartÄ±yoruz. BirÃ§ok bilgisayar sistemi
gibi bu sistem de [Memory Mapped
I/O](https://en.wikipedia.org/wiki/Memory-mapped_I/O_and_port-mapped_I/O)
yapÄ±sÄ±nda. UART, PLIC (Interrupt Controller) gibi donanÄ±mlarÄ±n hepsi iÅŸlemcinin
bellek haritasÄ±nda birer bellek alanÄ± gibi duruyorlar. Yani 0-2GB (`0x80000000`)
arasÄ± alan gÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re donanÄ±ma rezerve edilmiÅŸ, sonrasÄ±nda RAM baÅŸlÄ±yor.
Bizim durumda RAM 128 MB ile sÄ±nÄ±rlÄ± ve bu xv6'nÄ±n kodu iÃ§erisine de gÃ¶mÃ¼lmÃ¼ÅŸ
durumda.

### Process Bellek HaritasÄ±

Kernelin kendisi ve Ã§alÄ±ÅŸan her bir process virtual memory Ã¼zerinden Ã§alÄ±ÅŸmaktadÄ±r.
Yani gÃ¶rdÃ¼kleri bellek aslÄ±nda bir ilÃ¼zyon! BahsettiÄŸim paging mekanizmasÄ± ile
elbette gerÃ§ek bellekte, yani bu Ã¶rnekte 128 MiB'lik bellekte, karÅŸÄ±lÄ±klarÄ±
var (ya da bazen yok, sonuÃ§ta virtual, swap edilmiÅŸse? ğŸ™„). xv6 Ã¼zerinde Ã§alÄ±ÅŸan
her bir process aynÄ± virtual memory'yi gÃ¶rÃ¼yor, kernelde farklÄ±lÄ±klar var
anladÄ±ÄŸÄ±m kadarÄ±yla ama konumuz ÅŸimdilik user space process'ler.

xv6, varsayÄ±lan olarak 4 KiB yani 4096 byte'lÄ±k page size ile Ã§alÄ±ÅŸÄ±r:

```{code-block} c
:caption: kernel/riscv.h
:lineno-start: 335
:emphasize-lines: 1

#define PGSIZE 4096 // bytes per page
#define PGSHIFT 12  // bits of offset within a page
```

Yani bu demek oluyor ki process'lerin gÃ¶rdÃ¼ÄŸÃ¼ bellek 4096 byte'lÄ±k parÃ§alara
ayrÄ±lmÄ±ÅŸtÄ±r, 128 M'lik bellek de aynÄ± boyutta parÃ§alara ayrÄ±lmÄ±ÅŸtÄ±r, bunlara
page diyoruz. Process'in gÃ¶rdÃ¼ÄŸÃ¼ page'ler, gerÃ§ek page'lere herhangi bir
kombinasyonla eÅŸlenebilir. Bu iÅŸletim sisteminin sorumluluÄŸundadÄ±r. KuralÄ±
iÅŸletim sistemi koyar fakat bu kurala gÃ¶re bu dÃ¶nÃ¼ÅŸÃ¼mleri RISC-V iÅŸlemcisinin
kendisi yapar yani donanÄ±mda yapÄ±lÄ±r. Onun iÃ§in Ã¶nceki yazÄ±larÄ±n birinde OS
**policy** belirler, donanÄ±m **implementation** yapar demiÅŸtim, neyse.

**Peki user space process'ler yani Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z programlar nasÄ±l bir bellek
gÃ¶rÃ¼yor?**

```{figure} assets/os-ve-bellek-process-vm.png
:align: center

Process'lerin gÃ¶rdÃ¼ÄŸÃ¼ virtual memory. TÄ±rtÄ±klÄ± Ã§izgilerle Ã§izim saÄŸ tarafa
doÄŸru uzuyor ama o kÄ±sma sonraki yazÄ±larda bakacaÄŸÄ±z. ğŸ™‚

[Kaynak](https://pdos.csail.mit.edu/6.828/2023/xv6/book-riscv-rev3.pdf)
```

Ä°ÅŸte bu ÅŸekilde! Programlar diskte duruyor biz bunlarÄ± Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z zaman
RAM'e aÃ§Ä±lÄ±yorlar. Bunu iÅŸletim sistemi yapÄ±yor. ProgramlarÄ±n iÃ§erisinde Ã§eÅŸitli
*section* lar bulunuyor. `text` isimli section CPU'da Ã§alÄ±ÅŸacak kodu iÃ§eren
kÄ±sÄ±m yani CPU komutlarÄ±. Ä°ÅŸte bu kÄ±sÄ±m adres 0'dan baÅŸlanarak belleÄŸe
yerleÅŸtiriliyor, ama virtual memory adresi bÃ¶yle. GerÃ§ek fiziksel adres bambaÅŸka
olabilir. Åu an sadece sanal adreslerden konuÅŸuyoruz. `data` kÄ±smÄ±, programÄ±n
verileri. Mesela bir C programÄ±nda oluÅŸturduÄŸumuz statik Ã¶mÃ¼rlÃ¼ deÄŸiÅŸkenler
(global deÄŸiÅŸkenler, statik yerel deÄŸiÅŸkenler) bu alana yerleÅŸtiriliyorlar.
`stack`, Ã§alÄ±ÅŸacak program iÃ§erisinde bulunan bir kÄ±sÄ±m deÄŸil. Yine C'den
dÃ¼ÅŸÃ¼necek olursak fonksiyon Ã§aÄŸrÄ±larÄ±nda argÃ¼man ve dÃ¶nÃ¼ÅŸ deÄŸerlerinin
geÃ§irilmesi buradan yapÄ±lÄ±yor ve otomatik Ã¶mÃ¼rlÃ¼ yerel deÄŸiÅŸkenler stack
Ã¼zerinde yaratÄ±lÄ±yorlar. xv6'da stack boyutu runtime sÄ±rasÄ±nda deÄŸiÅŸmemektedir
ve 1 page size kadardÄ±r, yani varsayÄ±lan olarak 4096 byte.`data` ile `stack`
arasÄ±nda bir *guard page* var. Bunun amacÄ± stack taÅŸmalarÄ±nÄ± yakalayabilmek,
detaylarÄ±na bakacaÄŸÄ±z. Daha yukarÄ±da ise `heap` yer alÄ±yor. BurasÄ± dinamik
bellek yÃ¶netimi ile iÅŸletim sisteminden Ã§alÄ±ÅŸma sÄ±rasÄ±nda yani runtime sÄ±rasÄ±nda
bellek tahsis edilen yer. `heap` alanÄ±nÄ±n boyutu, Ã§alÄ±ÅŸma sÄ±rasÄ±nda program
tarafÄ±ndan yapÄ±lan `sbrk()` sistem Ã§aÄŸrÄ±sÄ± ile deÄŸiÅŸtirilebiliyor. Yani iÅŸletim
sisteminden daha Ã§ok bellek isteyebiliyoruz. C'de kullandÄ±ÄŸÄ±mÄ±z `malloc()` ve
benzeri fonksiyonlar da arka planda bunu yapÄ±yorlar. Runtime sÄ±rasÄ±nda boyutu
deÄŸiÅŸtirilebilen tek alan `heap` tir. BelleÄŸin en tepesinde ise `trapframe` ve
`trampoline` isimli iki page var. Bunlar user space ve kernel space arasÄ±
geÃ§iÅŸler, context switch iÅŸleri iÃ§in, sonra bakarÄ±z.

Virtual memory'nin tepe deÄŸeri `MAXVA` sembolik sabiti ile belirlenmiÅŸtir.

```{code-block} c
:caption: kernel/riscv.h
:lineno-start: 359
:emphasize-lines: 5

// one beyond the highest possible virtual address.
// MAXVA is actually one bit less than the max allowed by
// Sv39, to avoid having to sign-extend virtual addresses
// that have the high bit set.
#define MAXVA (1L << (9 + 9 + 9 + 12 - 1))
```

Burada `MAXVA` nÄ±n deÄŸeri tam 256 GiB olmaktadÄ±r! Elbette bu bellek sanal
bellektir, sonuÃ§ta elimizde fiziksel olarak 128M bellek var. Ä°ÅŸte bu arka planda
donanÄ±m tarafÄ±ndan gerÃ§ek belleÄŸe eÅŸleniyor. Ã‡alÄ±ÅŸan program oralara eriÅŸtiÄŸini
zannetse de fiziksel olarak baÅŸka adreslere eriÅŸiyor.

Ä°lerleyen yazÄ±larda bakarÄ±z, bizim sistemde virtual address 39-bit oluyor. Fakat
burada bir bit daha kÄ±sÄ±p 38-bit ile sÄ±nÄ±rlamÄ±ÅŸlar. Yani 39-bitlik sanal bellek
adresinin MSB'si her zaman 0 bu sistemde. Bu aralÄ±ÄŸÄ± 512 GiB'ten 256 GiB'e
dÃ¼ÅŸÃ¼rÃ¼yor ama zaten sayÄ±lar Ã§ok bÃ¼yÃ¼k. AvantajÄ± da ÅŸu diye anlÄ±yorum, ileride
kernel kodlarÄ±na bakarÄ±z: Ola ki iki 39-bit'lik sayÄ±yÄ± karÅŸÄ±laÅŸtÄ±rmaya vs
sokarsak C'de bu sayÄ±larÄ±n sign bit extension ile negatif sayÄ± gibi extend
edilmesinin ve hatalÄ± karÅŸÄ±laÅŸtÄ±rma yapÄ±lmasÄ±nÄ±n Ã¶nÃ¼ne geÃ§elim diye MSB her
zaman 0 tutulmuÅŸ diye anlÄ±yorum. Bu C kurallarÄ± ilgili bir ÅŸey ve bir nevi
[defensive programming](https://en.wikipedia.org/wiki/Defensive_programming)
Ã¶rneÄŸi.

Son olarak `RXWU` gibi karakterlerin anlamÄ±na bakalÄ±m. RISC-V iÅŸlemcisinde
page'lere Ã§eÅŸitli *attribute* lar atanabiliyor. Ã–rneÄŸin bir page sadece okunabilir,
Ã§alÄ±ÅŸtÄ±rÄ±labilir veya yazÄ±labilir gibi iÅŸaretlenebiliyor. Bunun amacÄ± olasÄ±
program hatalarÄ±nÄ±n programÄ± bozmasÄ±nÄ± Ã¶nlemek. Ã–rneÄŸin `text` alanÄ±nÄ±n Ã§alÄ±ÅŸtÄ±rÄ±labilir
koddan oluÅŸtuÄŸunu sÃ¶ylemiÅŸtik. Onun iÃ§in bu alanÄ±n `W` yetkisine sahip olmasÄ±na
gerek yok, Ã¼zerine yazma yapmayacaÄŸÄ±z. EÄŸer yanlÄ±ÅŸlÄ±kla yazma yaparsak, diyelim
ki programda bir bug var bu sefer iÅŸlemci bunu engelleyecektir.

- `R` okunabilir page
- `X` execute edilebilir yani Ã§alÄ±ÅŸtÄ±rÄ±labilir page. Buradakiler CPU Ã¼zerinde
  Ã§alÄ±ÅŸtÄ±rÄ±labilir.
- `W` yazÄ±labilir page
- `U` user modda eriÅŸilebilir page

Bir de page iÃ§in `V` yani valid flag'i var ama ÅŸu an konumuz dÄ±ÅŸÄ±nda.

EÄŸer kullancÄ±nÄ±n Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ± program, ilgili page'in Ã¶zelliÄŸine uymayan bir
iÅŸlem yaparsa iÅŸlemci bir exception Ã¼retiyor ve bununla iÅŸletim sistemi
ilgileniyor. Ã–rneÄŸin kullanÄ±cÄ± programÄ± `trampoline` ve `trapframe` e eriÅŸemez,
`U` Ã¶zelliÄŸi yok. `data` kÄ±smÄ±ndaki bir ÅŸeyi CPU'da Ã§alÄ±ÅŸtÄ±ramaz, `X` yok gibi.

```{attention}
Her process'in virtual memory gÃ¶rÃ¼nÃ¼mÃ¼ aynÄ± olsa da fiziksel belleÄŸe olan eÅŸleÅŸmesi
farklÄ± olacaktÄ±r. Her process iÃ§in kernel bir adet eÅŸleÅŸme tablosu tutmaktadÄ±r.
Sanal page'ler ile gerÃ§ek page'ler arasÄ± eÅŸleÅŸmeyi gÃ¶steren bu tablonun adÄ±
**page table** dÄ±r. Bunun kernel seviyesinde nasÄ±l gerÃ§ekleÅŸtirildiÄŸine sonra
bakarÄ±z.
```

## Kaynaklar

- <https://www.youtube.com/watch?v=Hr8Dck3re3k>
- <https://www.youtube.com/watch?v=o91pWKnr0Mk>
- <https://www.youtube.com/watch?v=SGeDjFoYAis>
- <https://en.wikipedia.org/wiki/Memory_segmentation>
- <https://lass.cs.umass.edu/~shenoy/courses/fall12/lectures/Lec12.pdf>
- <https://pages.cs.wisc.edu/~remzi/OSTEP/vm-segmentation.pdf>
- <https://www.youtube.com/watch?v=-DTXcfBW4NQ>
- <http://staff.um.edu.mt/csta1/courses/lectures/csm202/os10.html>
- <https://lass.cs.umass.edu/~shenoy/courses/fall12/lectures/Lec12.pdf>
- ğŸŒŸ Modern Operating Systems, 4th Edition, Tanenbaum. Chapter 3 Memory Management.
  `978-0133591620`
- <https://pdos.csail.mit.edu/6.828/2023/xv6/book-riscv-rev3.pdf>
- <https://www.youtube.com/watch?v=yfqxa-TYdFU>

[^1f]: <https://terimler.org/>
[^2f]: <https://en.wikipedia.org/wiki/Page_(computer_memory)>
